{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"collect movie data using webscraping in csv fle .ipynb","provenance":[],"authorship_tag":"ABX9TyNvwhegpAyhB8jzifoZK/0u"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"BVUUGl7jZKOU","colab_type":"code","colab":{}},"source":["import requests\n","from requests import get\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import numpy as np\n","\n","##https://medium.com/better-programming/how-to-scrape-multiple-pages-of-a-website-using-a-python-web-scraper-4e2c641cff8\n","\n","url = \"https://www.imdb.com/search/title/?groups=top_1000&ref_=adv_prv\"\n","headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n","results = requests.get(url, headers=headers)\n","\n","soup = BeautifulSoup(results.text, \"html.parser\")\n","\n","#initiate data storage\n","titles = []\n","years = []\n","time = []\n","imdb_ratings = []\n","metascores = []\n","votes = []\n","us_gross = []\n","\n","movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n","\n","#our loop through each container\n","for container in movie_div:\n","\n","        #name\n","        name = container.h3.a.text\n","        titles.append(name)\n","        \n","        #year\n","        year = container.h3.find('span', class_='lister-item-year').text\n","        years.append(year)\n","\n","        # runtime\n","        runtime = container.p.find('span', class_='runtime').text if container.p.find('span', class_='runtime').text else '-'\n","        time.append(runtime)\n","\n","        #IMDb rating\n","        imdb = float(container.strong.text)\n","        imdb_ratings.append(imdb)\n","\n","        #metascore\n","        m_score = container.find('span', class_='metascore').text if container.find('span', class_='metascore') else '-'\n","        metascores.append(m_score)\n","\n","        #there are two NV containers, grab both of them as they hold both the votes and the grosses\n","        nv = container.find_all('span', attrs={'name': 'nv'})\n","        \n","        #filter nv for votes\n","        vote = nv[0].text\n","        votes.append(vote)\n","        \n","        #filter nv for gross\n","        grosses = nv[1].text if len(nv) > 1 else '-'\n","        us_gross.append(grosses)\n","\n","#pandas dataframe        \n","movies = pd.DataFrame({\n","'movie': titles,\n","'year': years,\n","'timeMin': time,\n","'imdb': imdb_ratings,\n","'metascore': metascores,\n","'votes': votes,\n","'us_grossMillions': us_gross,\n","})\n","\n","#cleaning data \n","movies['year'] = movies['year'].str.extract('(\\d+)').astype(int)\n","movies['timeMin'] = movies['timeMin'].str.extract('(\\d+)').astype(int)\n","movies['metascore'] = movies['metascore'].astype(int)\n","movies['votes'] = movies['votes'].str.replace(',', '').astype(int)\n","movies['us_grossMillions'] = movies['us_grossMillions'].map(lambda x: x.lstrip('$').rstrip('M'))\n","movies['us_grossMillions'] = pd.to_numeric(movies['us_grossMillions'], errors='coerce')\n","\n","#add dataframe to csv file named 'movies.csv'\n","movies.to_csv('movies.csv')"],"execution_count":null,"outputs":[]}]}